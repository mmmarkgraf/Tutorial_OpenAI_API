{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This is a short tutorial to:\n",
    "    - Connect to the OpenAI API\n",
    "    - Fine-tune the model to create a chatbot that provides the day's events when greeted (Transfer Learning)\n",
    "    - Wrapping the AI in a simple UI app to allow interactions with the AI\n",
    "\n",
    "The \"tone\" or persona of the AI will be defined as a \"Marline\" who is a witty, dramatic chatbot who loves to give the gossip.\n",
    "\n",
    "This example follows the Medium article: \n",
    "\n",
    "\n",
    "An OpenAI account is required to use the API.\n",
    "\n",
    "'''\n",
    "\n",
    "# Importing libraries\n",
    "import os, openai, json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Input your OpenAI Secret Key:\n",
    "os.environ['OPENAI_API_KEY'] = 'YOUR OPENAI SECRET KEY'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Connecting to the OpenAI API\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Loading in the fine-tuning dataset.\n",
    "The dataset is a CSV that contains the information on the persona and example prompts and responses.\n",
    "There is the usage of \"multi-turn chat\" as \"weight\" (0 or 1 values) are used in the responses.\n",
    "However, only one example truly utilizes the weights.\n",
    "\n",
    "There are only 10 examples in this dataset but it is recommened by the OpenAI documentation that 50-100 examples be provided for better tuning:\n",
    "https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset#example-count-recommendations\n",
    "\n",
    "(10 examples are the minimum requirement for fine-tuning.)\n",
    "\n",
    "'''\n",
    "\n",
    "# Loading in the fine-tuning dataset\n",
    "df = pd.read_csv('marline_fine_tuning_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "From the OpenAI documentation, the fine-tuning process follows this format: https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset#multi-turn-chat-examples\n",
    "\n",
    "{\"messages\": \n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, \n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"Paris\", \"weight\": 0}, \n",
    "        {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\", \"weight\": 1}\n",
    "    ]\n",
    "}\n",
    "\n",
    "*** Since this is using the \"weight\" argument, this is more aligned with the multi-turn chat format (shown above) rather than the more simple singe example format.\n",
    "\n",
    "'''\n",
    "\n",
    "# Setting up the format to be used by OpenAI to fine-tune:\n",
    "fine_tuning_list = []\n",
    "\n",
    "for id in df['id'].unique():\n",
    "\n",
    "    messages_list = []\n",
    "\n",
    "    for index, row in df[df['id'] == id].iterrows():\n",
    "        \n",
    "        if pd.isna(row['weight']):\n",
    "            inner_dict = {\"role\": row['role'], \"content\": row['content']}\n",
    "        else:\n",
    "            inner_dict = {\"role\": row['role'], \"content\": row['content'], \"weight\": row['weight']}\n",
    "\n",
    "        messages_list.append(inner_dict)\n",
    "        \n",
    "    \n",
    "    fine_tuning_list.append({\"messages\": messages_list})\n",
    "\n",
    "\n",
    "# Converting the list to a JSONL file (JSON Lines)\n",
    "with open('marline_fine_tuning.jsonl', 'w') as f:\n",
    "    for entry in fine_tuning_list:\n",
    "        f.write(json.dumps(entry))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "(Skippable)\n",
    "\n",
    "Validating the JSON file, token counting, and cost estimate using the Python script provided by OpenAI:\n",
    "https://cookbook.openai.com/examples/chat_finetuning_data_prep\n",
    "\n",
    "Unfornately, the token counting and cost estimation does not work for the multi-turn chat format because the \"weight\" arugment is a numerical data type and the Python script only coverts strings to tokens.\n",
    "\n",
    "Since only 10 examples were created, the cost should not be significant enough to worry about.\n",
    "\n",
    "'''\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"marline_fine_tuning.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "For the model to find the fine-tuning dataset/JSONL, it needs to be uploaded to the OpenAI platform.\n",
    "Then a model needs to be selected and trained.\n",
    "\n",
    "Models that can be fine-tuned: https://platform.openai.com/docs/guides/fine-tuning#which-models-can-be-fine-tuned\n",
    "\n",
    "'''\n",
    "\n",
    "# Uploading the JSON file to OpenAI\n",
    "upload_info = client.files.create(\n",
    "  file=open(\"marline_fine_tuning.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print('Uploaded File Information: ', upload_info)\n",
    "\n",
    "# Selecting the model to fine-tune\n",
    "fine_tuning_info = client.fine_tuning.jobs.create(\n",
    "  training_file=upload_info.id, # This is the \"id\" attribute from the object returned by OpenAI for uploading the fine-tuning dataset\n",
    "  model=\"gpt-4o-mini-2024-07-18\", \n",
    "  suffix=\"marline_chatbox\" # Giving an addition name identifier to easily distinguish in the future\n",
    ")\n",
    "\n",
    "print('Fine Tuning Job Information: ', client.fine_tuning.jobs.retrieve(fine_tuning_info.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check the status of the fine-tuning job by running:\n",
    "\n",
    "trained_model_info = client.fine_tuning.jobs.retrieve(fine_tuning_info.id)\n",
    "print('Fine Tuned Model Information: ', trained_model_info)\n",
    "\n",
    "'''\n",
    "\n",
    "Similar to the code to fine tune a model, an object is returned with information about the fine-tuning job. The job \"id\" is used to pass as an argument to check on the status of the job.\n",
    "An email should be sent to the email address associated with the OpenAI account when the fine-tuning job is completed.\n",
    "Or, if using code to check for completion, the atribute \"finished_at\" can be checked to see if the job is complete.\n",
    "Either way, the name of the fine-tuned model is returned in the \"fine_tuned_model\" attribute.\n",
    "\n",
    "You can also check on the status of the fine-tuning job/models on the OpenAI website under the \"Dashboard\" >> \"Fine-Tuning\" section.\n",
    "This is also a nice method for finding the name of the fine-tuned model.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Testing the trained model.\n",
    "\n",
    "'''\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=trained_model_info.fine_tuned_model, # Trained model name\n",
    "  messages=[\n",
    "    {'role': 'system', 'content': 'Marline is a witty, dramatic, and gossipy informative chatbot.'},\n",
    "    {'role': 'user', 'content': 'Tell me a story.'}\n",
    "  ],\n",
    "  temperature= 0.8 # Determines the \"creativity\"/\"randomness\" of the response. Higher = more random. (Ranges from 0-2)\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
